# -*- coding: utf-8 -*-
"""spacy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_AhvQXfldbY5rzEwXjAOs8irAHF98zIp

SPacy- NLP package
"""

!pip install spacy

import spacy
from spacy.lang.en import English
nlp = English()

doc = nlp("I am stressed and I have a lot of thoughts in my mind. I want to relax.")
for token in doc:
    print(token.text)

doc.text

span= doc[9:13]
print(span.text)

for word in doc:
    lexeme = doc.vocab[word.text]
    print(lexeme.text, lexeme.orth, lexeme.orth_, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,
            lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)

"""nlp model"""

nlp = spacy.load("en_core_web_sm")

doc = nlp("I am stressed and I have a lot of thoughts in my mind. I want to relax.")
for token in doc:
    print(token.text,"\t", token.pos_,"\t", token.tag_)

"""explanation of tag"""

spacy.explain("PRP")

from spacy.lang.en.stop_words import STOP_WORDS
print(STOP_WORDS)

"""Removing stop words"""

filtered_sentence =[]
doc = nlp("I am stressed and I have a lot of thoughts in my mind. I want to relax.")
for word in doc:
    if  word.is_stop == False:
        filtered_sentence.append(word)
print(doc.text)
print(filtered_sentence)

"""Lemmatization - identifying the base form of the word"""

for token in doc:
    print(token.text , token.lemma_)

for token in doc.noun_chunks:
    print(token.text)

for token in doc.noun_chunks:
    print(token.root.text)

for token in doc.noun_chunks:
    print(token.root.head.text)

for word in doc:
    print(word.text, word.dep_)

spacy.displacy.render(doc, style='dep',jupyter= True)